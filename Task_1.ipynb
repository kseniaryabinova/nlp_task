{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from string import punctuation\n",
    "\n",
    "import nltk\n",
    "import pymorphy2\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.sampler import RandomSampler, SequentialSampler\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from torchnlp.word_to_vector import FastText\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "torch.manual_seed(12)\n",
    "torch.cuda.manual_seed(12)\n",
    "np.random.seed(12)\n",
    "random.seed(12)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'women-clothing-accessories.3-class.balanced.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path, sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiny EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>качество плохое пошив ужасный (горловина напер...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Товар отдали другому человеку, я не получила п...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ужасная синтетика! Тонкая, ничего общего с пре...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>товар не пришел, продавец продлил защиту без м...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Кофточка голая синтетика, носить не возможно.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89995</th>\n",
       "      <td>сделано достаточно хорошо. на ткани сделан рис...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89996</th>\n",
       "      <td>Накидка шикарная. Спасибо большое провдо линяе...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89997</th>\n",
       "      <td>спасибо большое ) продовца рекомендую.. заказа...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89998</th>\n",
       "      <td>Очень довольна заказом! Меньше месяца в РБ.  К...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89999</th>\n",
       "      <td>хорошая куртка. постороннего запаха нет. швы р...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      качество плохое пошив ужасный (горловина напер...  negative\n",
       "1      Товар отдали другому человеку, я не получила п...  negative\n",
       "2      Ужасная синтетика! Тонкая, ничего общего с пре...  negative\n",
       "3      товар не пришел, продавец продлил защиту без м...  negative\n",
       "4          Кофточка голая синтетика, носить не возможно.  negative\n",
       "...                                                  ...       ...\n",
       "89995  сделано достаточно хорошо. на ткани сделан рис...  positive\n",
       "89996  Накидка шикарная. Спасибо большое провдо линяе...  positive\n",
       "89997  спасибо большое ) продовца рекомендую.. заказа...  positive\n",
       "89998  Очень довольна заказом! Меньше месяца в РБ.  К...  positive\n",
       "89999  хорошая куртка. постороннего запаха нет. швы р...  positive\n",
       "\n",
       "[90000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, есть ли дизбаланс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f35b84d55f8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['sentiment'].value_counts().plot(kind='pie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дизбаланса нет, супер!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Препроцессинг\n",
    "\n",
    "Загружаем стоп-слова и лемматизаторы для английского и для русского (потому что в датасете перемешанные языки)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ksenia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "russian_stopwords = nltk.corpus.stopwords.words(\"russian\")\n",
    "english_stopwords = nltk.corpus.stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus_lemmatizer = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ksenia/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/ksenia/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "eng_lemmatizer = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем токенайзер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем резулярные выражения для русского и английского языков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus_pattern = re.compile(r'[А-я]+')\n",
    "eng_pattern = re.compile(r'[A-z]+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомогательные функции для предобработки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": nltk.corpus.wordnet.ADJ,\n",
    "                \"N\": nltk.corpus.wordnet.NOUN,\n",
    "                \"V\": nltk.corpus.wordnet.VERB,\n",
    "                \"R\": nltk.corpus.wordnet.ADV}\n",
    "    return tag_dict.get(tag, nltk.corpus.wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаляем из списка стоп-слова, которые могут влиять на таргет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove(word_list, words_to_remove):\n",
    "    for word in words_to_remove:\n",
    "        try:\n",
    "            word_list.remove(word)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "remove(russian_stopwords, ('не', 'никогда', 'хорошо', 'конечно', 'лучше', 'нельзя', 'наконец', 'еще', 'без'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для препроцессинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_line(row):\n",
    "    line = row['review'].lower()\n",
    "    tokens = tokenizer.tokenize(line)\n",
    "    \n",
    "    tokens = [token for token in tokens if token not in russian_stopwords\\\n",
    "              and token != \" \" \\\n",
    "              and token.strip() not in punctuation]\n",
    "    \n",
    "    tokens = [token for token in tokens if token not in english_stopwords\\\n",
    "              and token != \" \" \\\n",
    "              and token.strip() not in punctuation]\n",
    "    \n",
    "    normal_forms = []\n",
    "    for token in tokens:\n",
    "        if rus_pattern.match(token):\n",
    "            normal_form = rus_lemmatizer.parse(token)[0].normal_form\n",
    "            if normal_form not in russian_stopwords:    \n",
    "                normal_forms.append(normal_form)\n",
    "        elif eng_pattern.match(token):\n",
    "            normal_form = eng_lemmatizer.lemmatize(token, get_wordnet_pos(token))\n",
    "            if normal_form not in english_stopwords:    \n",
    "                normal_forms.append(normal_form)\n",
    "                \n",
    "    row['tokens'] = normal_forms\n",
    "    row['strat_kfold'] = '{}_{}'.format(row['sentiment'], len(normal_forms))\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запускаем препроцессинг (для всего датасета он занимает примерно 3 минуты)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90000/90000 [03:14<00:00, 463.31it/s]\n"
     ]
    }
   ],
   "source": [
    "df = df.progress_apply(preprocess_line, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokens</th>\n",
       "      <th>strat_kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>качество плохое пошив ужасный (горловина напер...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[качество, плохой, пошив, ужасный, горловина, ...</td>\n",
       "      <td>negative_21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Товар отдали другому человеку, я не получила п...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[товар, отдать, человек, не, получить, посылка...</td>\n",
       "      <td>negative_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ужасная синтетика! Тонкая, ничего общего с пре...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[ужасный, синтетик, тонкий, общий, представить...</td>\n",
       "      <td>negative_20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>товар не пришел, продавец продлил защиту без м...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[товар, не, прийти, продавец, продлить, защита...</td>\n",
       "      <td>negative_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Кофточка голая синтетика, носить не возможно.</td>\n",
       "      <td>negative</td>\n",
       "      <td>[кофточка, голый, синтетик, носить, не, возможно]</td>\n",
       "      <td>negative_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89995</th>\n",
       "      <td>сделано достаточно хорошо. на ткани сделан рис...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[сделать, достаточно, хорошо, ткань, сделать, ...</td>\n",
       "      <td>positive_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89996</th>\n",
       "      <td>Накидка шикарная. Спасибо большое провдо линяе...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[накидка, шикарный, спасибо, большой, провдо, ...</td>\n",
       "      <td>positive_16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89997</th>\n",
       "      <td>спасибо большое ) продовца рекомендую.. заказа...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[спасибо, большой, продовца, рекомендовать, за...</td>\n",
       "      <td>positive_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89998</th>\n",
       "      <td>Очень довольна заказом! Меньше месяца в РБ.  К...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[очень, довольный, заказ, маленький, месяц, рб...</td>\n",
       "      <td>positive_15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89999</th>\n",
       "      <td>хорошая куртка. постороннего запаха нет. швы р...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[хороший, куртка, посторонний, запах, шов, ров...</td>\n",
       "      <td>positive_16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment  \\\n",
       "0      качество плохое пошив ужасный (горловина напер...  negative   \n",
       "1      Товар отдали другому человеку, я не получила п...  negative   \n",
       "2      Ужасная синтетика! Тонкая, ничего общего с пре...  negative   \n",
       "3      товар не пришел, продавец продлил защиту без м...  negative   \n",
       "4          Кофточка голая синтетика, носить не возможно.  negative   \n",
       "...                                                  ...       ...   \n",
       "89995  сделано достаточно хорошо. на ткани сделан рис...  positive   \n",
       "89996  Накидка шикарная. Спасибо большое провдо линяе...  positive   \n",
       "89997  спасибо большое ) продовца рекомендую.. заказа...  positive   \n",
       "89998  Очень довольна заказом! Меньше месяца в РБ.  К...  positive   \n",
       "89999  хорошая куртка. постороннего запаха нет. швы р...  positive   \n",
       "\n",
       "                                                  tokens  strat_kfold  \n",
       "0      [качество, плохой, пошив, ужасный, горловина, ...  negative_21  \n",
       "1      [товар, отдать, человек, не, получить, посылка...   negative_9  \n",
       "2      [ужасный, синтетик, тонкий, общий, представить...  negative_20  \n",
       "3      [товар, не, прийти, продавец, продлить, защита...  negative_10  \n",
       "4      [кофточка, голый, синтетик, носить, не, возможно]   negative_6  \n",
       "...                                                  ...          ...  \n",
       "89995  [сделать, достаточно, хорошо, ткань, сделать, ...  positive_13  \n",
       "89996  [накидка, шикарный, спасибо, большой, провдо, ...  positive_16  \n",
       "89997  [спасибо, большой, продовца, рекомендовать, за...   positive_6  \n",
       "89998  [очень, довольный, заказ, маленький, месяц, рб...  positive_15  \n",
       "89999  [хороший, куртка, посторонний, запах, шов, ров...  positive_16  \n",
       "\n",
       "[90000 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем эмбеддинги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_embeddings = FastText(language='ru')\n",
    "en_embeddings = FastText(language='en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разбиение на трейн и тест"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобъем датасет с помощью приема, который используется для кросс-валидации. Я решила так поступить для того, чтобы распределения трейна и теста были как можно более похожими"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ksenia/frow_home_projects/env/lib/python3.6/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "for fold_number, (train_index, val_index) in enumerate(stratified_kfold.split(X=df.index, y=df['strat_kfold'])):\n",
    "    df.loc[df.iloc[val_index].index, 'fold'] = fold_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаляем строки, которые после препроцессинга растеряли все слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['tokens'].apply(len) != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokens</th>\n",
       "      <th>strat_kfold</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>качество плохое пошив ужасный (горловина напер...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[качество, плохой, пошив, ужасный, горловина, ...</td>\n",
       "      <td>negative_21</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Товар отдали другому человеку, я не получила п...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[товар, отдать, человек, не, получить, посылка...</td>\n",
       "      <td>negative_9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ужасная синтетика! Тонкая, ничего общего с пре...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[ужасный, синтетик, тонкий, общий, представить...</td>\n",
       "      <td>negative_20</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>товар не пришел, продавец продлил защиту без м...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[товар, не, прийти, продавец, продлить, защита...</td>\n",
       "      <td>negative_10</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Кофточка голая синтетика, носить не возможно.</td>\n",
       "      <td>negative</td>\n",
       "      <td>[кофточка, голый, синтетик, носить, не, возможно]</td>\n",
       "      <td>negative_6</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89995</th>\n",
       "      <td>сделано достаточно хорошо. на ткани сделан рис...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[сделать, достаточно, хорошо, ткань, сделать, ...</td>\n",
       "      <td>positive_13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89996</th>\n",
       "      <td>Накидка шикарная. Спасибо большое провдо линяе...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[накидка, шикарный, спасибо, большой, провдо, ...</td>\n",
       "      <td>positive_16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89997</th>\n",
       "      <td>спасибо большое ) продовца рекомендую.. заказа...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[спасибо, большой, продовца, рекомендовать, за...</td>\n",
       "      <td>positive_6</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89998</th>\n",
       "      <td>Очень довольна заказом! Меньше месяца в РБ.  К...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[очень, довольный, заказ, маленький, месяц, рб...</td>\n",
       "      <td>positive_15</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89999</th>\n",
       "      <td>хорошая куртка. постороннего запаха нет. швы р...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[хороший, куртка, посторонний, запах, шов, ров...</td>\n",
       "      <td>positive_16</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89788 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment  \\\n",
       "0      качество плохое пошив ужасный (горловина напер...  negative   \n",
       "1      Товар отдали другому человеку, я не получила п...  negative   \n",
       "2      Ужасная синтетика! Тонкая, ничего общего с пре...  negative   \n",
       "3      товар не пришел, продавец продлил защиту без м...  negative   \n",
       "4          Кофточка голая синтетика, носить не возможно.  negative   \n",
       "...                                                  ...       ...   \n",
       "89995  сделано достаточно хорошо. на ткани сделан рис...  positive   \n",
       "89996  Накидка шикарная. Спасибо большое провдо линяе...  positive   \n",
       "89997  спасибо большое ) продовца рекомендую.. заказа...  positive   \n",
       "89998  Очень довольна заказом! Меньше месяца в РБ.  К...  positive   \n",
       "89999  хорошая куртка. постороннего запаха нет. швы р...  positive   \n",
       "\n",
       "                                                  tokens  strat_kfold  fold  \n",
       "0      [качество, плохой, пошив, ужасный, горловина, ...  negative_21   0.0  \n",
       "1      [товар, отдать, человек, не, получить, посылка...   negative_9   2.0  \n",
       "2      [ужасный, синтетик, тонкий, общий, представить...  negative_20   1.0  \n",
       "3      [товар, не, прийти, продавец, продлить, защита...  negative_10   2.0  \n",
       "4      [кофточка, голый, синтетик, носить, не, возможно]   negative_6   2.0  \n",
       "...                                                  ...          ...   ...  \n",
       "89995  [сделать, достаточно, хорошо, ткань, сделать, ...  positive_13   0.0  \n",
       "89996  [накидка, шикарный, спасибо, большой, провдо, ...  positive_16   0.0  \n",
       "89997  [спасибо, большой, продовца, рекомендовать, за...   positive_6   3.0  \n",
       "89998  [очень, довольный, заказ, маленький, месяц, рб...  positive_15   2.0  \n",
       "89999  [хороший, куртка, посторонний, запах, шов, ров...  positive_16   2.0  \n",
       "\n",
       "[89788 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Датасет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс для конвертации токенов в тензоры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetRetriever(Dataset):\n",
    "    def __init__(self, df_dataset, max_amount_of_words):\n",
    "        super().__init__()\n",
    "        self.df_dataset = df_dataset\n",
    "        self.index_values = df_dataset.index.values\n",
    "        self.max_amount_of_words = max_amount_of_words\n",
    "        \n",
    "    def __getitem__(self, index: int):\n",
    "        row = self.df_dataset.loc[self.index_values[index]]\n",
    "        \n",
    "        tensor = torch.zeros([self.max_amount_of_words, 300], dtype=torch.float32)\n",
    "        counter = 0\n",
    "        \n",
    "        for token in row['tokens']:\n",
    "            if counter >= self.max_amount_of_words:\n",
    "                break\n",
    "            \n",
    "            if rus_pattern.match(token):\n",
    "                tensor[counter, :] = ru_embeddings[token]\n",
    "            elif eng_pattern.match(token):\n",
    "                tensor[counter, :] = en_embeddings[token]\n",
    "            \n",
    "            if torch.sum(tensor[counter, :]) != 0:\n",
    "                counter += 1\n",
    "                \n",
    "        label = 0\n",
    "        if row['sentiment'] == 'neautral':\n",
    "            label = 1\n",
    "        elif row['sentiment'] == 'positive':\n",
    "            label = 2\n",
    "            \n",
    "        # если ни один токен не имеет эмбеддинга, то устанавливаем лейбл = -1, \n",
    "        # чтобы потом отфильтровать этот тензор как невалидный\n",
    "        if torch.sum(tensor) == 0:\n",
    "            label = -1\n",
    "            \n",
    "        return tensor, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.index_values.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть фолд с номером 0 будет валидационной выборкой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_number = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DatasetRetriever(df[df['fold'] != fold_number], 120)\n",
    "val_dataset = DatasetRetriever(df[df['fold'] == fold_number], 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем, что датасет построился корректно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 300])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = train_dataset[0]\n",
    "data[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "инициализируем переменные для нейронки и загрузчика данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 128\n",
    "num_workers = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем загрузчики данных для трейна и валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    matrix_list = []\n",
    "    label_list = []\n",
    "    \n",
    "    for matrix, label in batch:\n",
    "        if label != -1:\n",
    "            matrix_list.append(matrix)\n",
    "            label_list.append(label)\n",
    "            \n",
    "    return matrix_list, label_list\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    sampler=RandomSampler(train_dataset),\n",
    "    pin_memory=False,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=False,\n",
    "    sampler=SequentialSampler(val_dataset),\n",
    "    pin_memory=False,\n",
    "    collate_fn=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я нашла статью (https://ieeexplore.ieee.org/document/8807792) от авторов датасета, и решила сделать похожую архитектуру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super(Model, self).__init__()\n",
    "                \n",
    "        dim1, dim2  = 8, 16\n",
    "        \n",
    "        self.cnn_layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(dim_in, dim1, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            torch.nn.BatchNorm1d(num_features=dim1),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Conv1d(dim1, dim2, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            torch.nn.BatchNorm1d(num_features=dim2),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.cnn_layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(dim_in, dim1, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            torch.nn.BatchNorm1d(num_features=dim1),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Conv1d(dim1, dim2, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            torch.nn.BatchNorm1d(num_features=dim2),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.cnn_layer3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(dim_in, dim1, kernel_size=5, stride=1, padding=2, bias=False),\n",
    "            torch.nn.BatchNorm1d(num_features=dim1),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Conv1d(dim1, dim2, kernel_size=5, stride=1, padding=2, bias=False),\n",
    "            torch.nn.BatchNorm1d(num_features=dim2),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.cnn_layer4 = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(dim_in, dim1, kernel_size=7, stride=1, padding=3, bias=False),\n",
    "            torch.nn.BatchNorm1d(num_features=dim1),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Conv1d(dim1, dim2, kernel_size=7, stride=1, padding=3, bias=False),\n",
    "            torch.nn.BatchNorm1d(num_features=dim2),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.cnn_layer5 = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(dim_in, dim1, kernel_size=9, stride=1, padding=4, bias=False),\n",
    "            torch.nn.BatchNorm1d(num_features=dim1),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Conv1d(dim1, dim2, kernel_size=9, stride=1, padding=4, bias=False),\n",
    "            torch.nn.BatchNorm1d(num_features=dim2),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.max_pool1 = torch.nn.MaxPool1d(kernel_size=2)\n",
    "        self.max_pool2 = torch.nn.MaxPool1d(kernel_size=2)\n",
    "        self.max_pool3 = torch.nn.MaxPool1d(kernel_size=2)\n",
    "        self.max_pool4 = torch.nn.MaxPool1d(kernel_size=2)\n",
    "        self.max_pool5 = torch.nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        self.linear1 = torch.nn.Linear(12000, dim_out)\n",
    "        \n",
    "    def forward(self, matrix):\n",
    "        x1 = self.cnn_layer1(matrix)\n",
    "        x2 = self.cnn_layer2(matrix)\n",
    "        x3 = self.cnn_layer3(matrix)\n",
    "        x4 = self.cnn_layer4(matrix)\n",
    "        x5 = self.cnn_layer5(matrix)\n",
    "        \n",
    "        x1 = self.max_pool1(x1)\n",
    "        x2 = self.max_pool2(x2)\n",
    "        x3 = self.max_pool3(x3)\n",
    "        x4 = self.max_pool4(x4)\n",
    "        x5 = self.max_pool5(x5)\n",
    "        \n",
    "        x1 = torch.flatten(x1, 1)\n",
    "        x2 = torch.flatten(x2, 1)\n",
    "        x3 = torch.flatten(x3, 1)\n",
    "        x4 = torch.flatten(x4, 1)\n",
    "        x5 = torch.flatten(x5, 1)\n",
    "        \n",
    "        x6 = torch.cat((x1, x2, x3, x4, x5), dim=1)\n",
    "        x7 = self.linear1(x6)\n",
    "        \n",
    "        return x7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем модель на девайс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 120 - максимальное количество слов, которые подаются на вход нейронке; 3 - количество классов\n",
    "model = Model(120, 3)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(nn_model, dataset_loader, loss_criterion, grad_optimizer):\n",
    "    running_loss = 0.0\n",
    "    nn_model.train()\n",
    "    \n",
    "    for batch_idx, (matrices, labels) in enumerate(dataset_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch_tensor = torch.stack(matrices).to(device)\n",
    "        labels_tensor = torch.tensor(labels).to(device)\n",
    "        \n",
    "        outputs = nn_model(batch_tensor)\n",
    "        loss = loss_criterion(outputs, labels_tensor)\n",
    "        loss.backward()\n",
    "        \n",
    "        grad_optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if batch_idx % 100 == 0 and batch_idx != 0:\n",
    "            print('batch #{}\\t accumulated_loss = {}\\t current_loss = {}'.format(\n",
    "                batch_idx, running_loss/batch_idx, loss.item()))\n",
    "            \n",
    "    return running_loss / len(dataset_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(nn_model, dataset_loader, loss_criterion):\n",
    "    running_loss = 0.0\n",
    "    accuracy = 0\n",
    "    pred_array = []\n",
    "    label_array = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        \n",
    "        for i, (matrices, labels) in enumerate(dataset_loader):\n",
    "            batch_tensor = torch.stack(matrices).to(device)\n",
    "            labels_tensor = torch.tensor(labels).to(device)\n",
    "\n",
    "            outputs = nn_model(batch_tensor)\n",
    "            loss = loss_criterion(outputs, labels_tensor)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            pred_array += torch.argmax(outputs, dim=1).tolist()\n",
    "            label_array += labels\n",
    "\n",
    "            accurate_predicted = torch.sum(torch.argmax(outputs, dim=1) == labels_tensor).item()\n",
    "            accuracy += accurate_predicted\n",
    "            \n",
    "    print('----------------------------------------------validation')\n",
    "    print('accumulated_loss:  ', running_loss/len(val_loader))\n",
    "    print('confusion_matrix:\\n', confusion_matrix(label_array, pred_array))\n",
    "    print('classification_report:\\n', classification_report(label_array, pred_array))\n",
    "    print('\\n\\n\\n')\n",
    "    \n",
    "    classification_report_dict = classification_report(label_array, pred_array, output_dict=True)    \n",
    "    macro_f1 = classification_report_dict['macro avg']['f1-score']\n",
    "    \n",
    "    return running_loss / len(dataset_loader), macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------epoch #0\n",
      "batch #100\t accumulated_loss = 1.024309542775154\t current_loss = 0.9400205016136169\n",
      "batch #200\t accumulated_loss = 0.9667309445142745\t current_loss = 0.8359429836273193\n",
      "batch #300\t accumulated_loss = 0.9258441617091496\t current_loss = 0.8597476482391357\n",
      "batch #400\t accumulated_loss = 0.8934870705008506\t current_loss = 0.7693899273872375\n",
      "batch #500\t accumulated_loss = 0.8700821202993393\t current_loss = 0.7895405888557434\n",
      "----------------------------------------------validation\n",
      "accumulated_loss:   0.7470575613035283\n",
      "confusion_matrix:\n",
      " [[4061 1658  312]\n",
      " [1599 3514  878]\n",
      " [ 416 1090 4514]]\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67      6031\n",
      "           1       0.56      0.59      0.57      5991\n",
      "           2       0.79      0.75      0.77      6020\n",
      "\n",
      "   micro avg       0.67      0.67      0.67     18042\n",
      "   macro avg       0.67      0.67      0.67     18042\n",
      "weighted avg       0.67      0.67      0.67     18042\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------epoch #1\n",
      "batch #100\t accumulated_loss = 0.7391747909784318\t current_loss = 0.708621084690094\n",
      "batch #200\t accumulated_loss = 0.7309211957454681\t current_loss = 0.7318717241287231\n",
      "batch #300\t accumulated_loss = 0.7243413329124451\t current_loss = 0.684998631477356\n",
      "batch #400\t accumulated_loss = 0.7231567980349064\t current_loss = 0.7173519730567932\n",
      "batch #500\t accumulated_loss = 0.7185742254257202\t current_loss = 0.7718797922134399\n",
      "----------------------------------------------validation\n",
      "accumulated_loss:   0.7047229426007875\n",
      "confusion_matrix:\n",
      " [[3857 1940  234]\n",
      " [1262 3959  770]\n",
      " [ 254 1132 4634]]\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.64      0.68      6031\n",
      "           1       0.56      0.66      0.61      5991\n",
      "           2       0.82      0.77      0.79      6020\n",
      "\n",
      "   micro avg       0.69      0.69      0.69     18042\n",
      "   macro avg       0.70      0.69      0.69     18042\n",
      "weighted avg       0.70      0.69      0.69     18042\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------epoch #2\n",
      "batch #100\t accumulated_loss = 0.6925538998842239\t current_loss = 0.738574206829071\n",
      "batch #200\t accumulated_loss = 0.6842500141263008\t current_loss = 0.6414860486984253\n",
      "batch #300\t accumulated_loss = 0.6810328181584676\t current_loss = 0.6947188377380371\n",
      "batch #400\t accumulated_loss = 0.6802612684667111\t current_loss = 0.6387498378753662\n",
      "batch #500\t accumulated_loss = 0.6774003540277481\t current_loss = 0.6934580206871033\n",
      "----------------------------------------------validation\n",
      "accumulated_loss:   0.688152510515401\n",
      "confusion_matrix:\n",
      " [[3851 1843  337]\n",
      " [1201 3716 1074]\n",
      " [ 216  829 4975]]\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.64      0.68      6031\n",
      "           1       0.58      0.62      0.60      5991\n",
      "           2       0.78      0.83      0.80      6020\n",
      "\n",
      "   micro avg       0.70      0.70      0.70     18042\n",
      "   macro avg       0.70      0.70      0.69     18042\n",
      "weighted avg       0.70      0.70      0.69     18042\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------epoch #3\n",
      "batch #100\t accumulated_loss = 0.6563131707906723\t current_loss = 0.6813098192214966\n",
      "batch #200\t accumulated_loss = 0.6534762340784073\t current_loss = 0.6590378880500793\n",
      "batch #300\t accumulated_loss = 0.6518556332588196\t current_loss = 0.6719297766685486\n",
      "batch #400\t accumulated_loss = 0.6532213106751442\t current_loss = 0.7242968082427979\n",
      "batch #500\t accumulated_loss = 0.6538408451080322\t current_loss = 0.622866153717041\n",
      "----------------------------------------------validation\n",
      "accumulated_loss:   0.6824375697424714\n",
      "confusion_matrix:\n",
      " [[4560 1208  263]\n",
      " [1972 3079  940]\n",
      " [ 366  747 4907]]\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.76      0.71      6031\n",
      "           1       0.61      0.51      0.56      5991\n",
      "           2       0.80      0.82      0.81      6020\n",
      "\n",
      "   micro avg       0.70      0.70      0.70     18042\n",
      "   macro avg       0.69      0.70      0.69     18042\n",
      "weighted avg       0.69      0.70      0.69     18042\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------epoch #4\n",
      "batch #100\t accumulated_loss = 0.6390811377763748\t current_loss = 0.6366385221481323\n",
      "batch #200\t accumulated_loss = 0.638970499932766\t current_loss = 0.6398045420646667\n",
      "batch #300\t accumulated_loss = 0.6359802852074306\t current_loss = 0.5661938190460205\n",
      "batch #400\t accumulated_loss = 0.6361320089548826\t current_loss = 0.6322434544563293\n",
      "batch #500\t accumulated_loss = 0.6358020973205566\t current_loss = 0.5855306386947632\n",
      "----------------------------------------------validation\n",
      "accumulated_loss:   0.6823499578405434\n",
      "confusion_matrix:\n",
      " [[4324 1334  373]\n",
      " [1633 3104 1254]\n",
      " [ 254  634 5132]]\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.72      0.71      6031\n",
      "           1       0.61      0.52      0.56      5991\n",
      "           2       0.76      0.85      0.80      6020\n",
      "\n",
      "   micro avg       0.70      0.70      0.70     18042\n",
      "   macro avg       0.69      0.70      0.69     18042\n",
      "weighted avg       0.69      0.70      0.69     18042\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------epoch #5\n",
      "batch #100\t accumulated_loss = 0.6284231859445571\t current_loss = 0.5619425773620605\n",
      "batch #200\t accumulated_loss = 0.6280124256014824\t current_loss = 0.5698757171630859\n",
      "batch #300\t accumulated_loss = 0.6227688815196355\t current_loss = 0.5811008810997009\n",
      "batch #400\t accumulated_loss = 0.6228246913850307\t current_loss = 0.6194124221801758\n",
      "batch #500\t accumulated_loss = 0.6207735099792481\t current_loss = 0.6957517862319946\n",
      "----------------------------------------------validation\n",
      "accumulated_loss:   0.688029923909147\n",
      "confusion_matrix:\n",
      " [[4790  975  266]\n",
      " [2248 2690 1053]\n",
      " [ 417  587 5016]]\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.79      0.71      6031\n",
      "           1       0.63      0.45      0.53      5991\n",
      "           2       0.79      0.83      0.81      6020\n",
      "\n",
      "   micro avg       0.69      0.69      0.69     18042\n",
      "   macro avg       0.69      0.69      0.68     18042\n",
      "weighted avg       0.69      0.69      0.68     18042\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------epoch #6\n",
      "batch #100\t accumulated_loss = 0.6128122419118881\t current_loss = 0.6528224349021912\n",
      "batch #200\t accumulated_loss = 0.6079251059889793\t current_loss = 0.5994218587875366\n",
      "batch #300\t accumulated_loss = 0.6085823427637418\t current_loss = 0.7015596032142639\n",
      "batch #400\t accumulated_loss = 0.6059153188765048\t current_loss = 0.5224641561508179\n",
      "batch #500\t accumulated_loss = 0.6069678410291671\t current_loss = 0.5691783428192139\n",
      "----------------------------------------------validation\n",
      "accumulated_loss:   0.6716561011025604\n",
      "confusion_matrix:\n",
      " [[4091 1757  183]\n",
      " [1380 3881  730]\n",
      " [ 250  998 4772]]\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.68      0.70      6031\n",
      "           1       0.58      0.65      0.61      5991\n",
      "           2       0.84      0.79      0.82      6020\n",
      "\n",
      "   micro avg       0.71      0.71      0.71     18042\n",
      "   macro avg       0.71      0.71      0.71     18042\n",
      "weighted avg       0.71      0.71      0.71     18042\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------epoch #7\n",
      "batch #100\t accumulated_loss = 0.5975080531835556\t current_loss = 0.5939178466796875\n",
      "batch #200\t accumulated_loss = 0.5963713751733303\t current_loss = 0.5491921305656433\n",
      "batch #300\t accumulated_loss = 0.5956972377498945\t current_loss = 0.5225892066955566\n",
      "batch #400\t accumulated_loss = 0.5950823500007391\t current_loss = 0.5806052684783936\n",
      "batch #500\t accumulated_loss = 0.5961745377182961\t current_loss = 0.6427921652793884\n",
      "----------------------------------------------validation\n",
      "accumulated_loss:   0.6758858238307524\n",
      "confusion_matrix:\n",
      " [[3717 2057  257]\n",
      " [1082 4012  897]\n",
      " [ 168  899 4953]]\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.62      0.68      6031\n",
      "           1       0.58      0.67      0.62      5991\n",
      "           2       0.81      0.82      0.82      6020\n",
      "\n",
      "   micro avg       0.70      0.70      0.70     18042\n",
      "   macro avg       0.71      0.70      0.70     18042\n",
      "weighted avg       0.71      0.70      0.70     18042\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------epoch #8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch #100\t accumulated_loss = 0.5894210895895958\t current_loss = 0.5734207630157471\n",
      "batch #200\t accumulated_loss = 0.5863297973573208\t current_loss = 0.6248311400413513\n",
      "batch #300\t accumulated_loss = 0.5827113109827041\t current_loss = 0.546962320804596\n",
      "batch #400\t accumulated_loss = 0.5849819654971361\t current_loss = 0.6233723759651184\n",
      "batch #500\t accumulated_loss = 0.5837674698233605\t current_loss = 0.5885387063026428\n",
      "----------------------------------------------validation\n",
      "accumulated_loss:   0.6801986870631366\n",
      "confusion_matrix:\n",
      " [[4373 1363  295]\n",
      " [1709 3258 1024]\n",
      " [ 270  719 5031]]\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.73      0.71      6031\n",
      "           1       0.61      0.54      0.58      5991\n",
      "           2       0.79      0.84      0.81      6020\n",
      "\n",
      "   micro avg       0.70      0.70      0.70     18042\n",
      "   macro avg       0.70      0.70      0.70     18042\n",
      "weighted avg       0.70      0.70      0.70     18042\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------epoch #9\n",
      "batch #100\t accumulated_loss = 0.5704020980000496\t current_loss = 0.44082602858543396\n",
      "batch #200\t accumulated_loss = 0.5696154983341694\t current_loss = 0.5561736822128296\n",
      "batch #300\t accumulated_loss = 0.5712120760480562\t current_loss = 0.5153032541275024\n",
      "batch #400\t accumulated_loss = 0.5727677681297064\t current_loss = 0.5700201988220215\n",
      "batch #500\t accumulated_loss = 0.5740241438746453\t current_loss = 0.5481931567192078\n",
      "----------------------------------------------validation\n",
      "accumulated_loss:   0.6810071493538332\n",
      "confusion_matrix:\n",
      " [[4221 1653  157]\n",
      " [1594 3728  669]\n",
      " [ 273 1036 4711]]\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.70      0.70      6031\n",
      "           1       0.58      0.62      0.60      5991\n",
      "           2       0.85      0.78      0.82      6020\n",
      "\n",
      "   micro avg       0.70      0.70      0.70     18042\n",
      "   macro avg       0.71      0.70      0.70     18042\n",
      "weighted avg       0.71      0.70      0.70     18042\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "checkpoints_path = 'checkpoints'\n",
    "os.makedirs(checkpoints_path, exist_ok=True)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(10):\n",
    "    print('----------------------------------------------epoch #{}'.format(epoch))\n",
    "    \n",
    "    train_loss = train_one_epoch(model, train_loader, criterion, optimizer)\n",
    "    val_loss, macro_f1_score = validate(model, val_loader, criterion)\n",
    "    \n",
    "    torch.save(model.state_dict(), os.path.join(\n",
    "        checkpoints_path, 'checkpoint_epoch_{}_f1_{}.pth'.format(epoch, int(macro_f1_score*100))))\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим графики лоссов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(range(len(train_losses))), train_losses)\n",
    "plt.plot(list(range(len(val_losses))), val_losses)\n",
    "plt.legend([\"train loss\", \"validation loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выбор модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбираем по f1-мере. берем веса, полученные на 6 эпохе "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(120, 3)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(os.path.join('checkpoints', 'checkpoint_epoch_6_f1_70.pth')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------validation\n",
      "accumulated loss:   0.6716561011025604\n",
      "accuracy:   0.7063518456933822\n",
      "confusion_matrix:\n",
      " [[4091 1757  183]\n",
      " [1380 3881  730]\n",
      " [ 250  998 4772]]\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.68      0.70      6031\n",
      "           1       0.58      0.65      0.61      5991\n",
      "           2       0.84      0.79      0.82      6020\n",
      "\n",
      "   micro avg       0.71      0.71      0.71     18042\n",
      "   macro avg       0.71      0.71      0.71     18042\n",
      "weighted avg       0.71      0.71      0.71     18042\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "accuracy = 0\n",
    "pred_array = []\n",
    "label_array = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    for i, (matrices, labels) in enumerate(val_loader):\n",
    "        batch_tensor = torch.stack(matrices).to(device)\n",
    "        labels_tensor = torch.tensor(labels).to(device)\n",
    "\n",
    "        outputs = model(batch_tensor)\n",
    "        loss = criterion(outputs, labels_tensor)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        pred_array += torch.argmax(outputs, dim=1).tolist()\n",
    "        label_array += labels\n",
    "\n",
    "        accurate_predicted = torch.sum(torch.argmax(outputs, dim=1) == labels_tensor).item()\n",
    "        accuracy += accurate_predicted\n",
    "\n",
    "print('----------------------------------------------validation')\n",
    "print('accumulated loss:  ', running_loss/len(val_loader))\n",
    "print('accuracy:  ', accuracy / len(label_array))\n",
    "print('confusion_matrix:\\n', confusion_matrix(label_array, pred_array))\n",
    "print('classification_report:\\n', classification_report(label_array, pred_array))\n",
    "print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report_dict = classification_report(label_array, pred_array, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro_f1_measure:  0.7087714879725104\n"
     ]
    }
   ],
   "source": [
    "print('macro_f1_measure: ', classification_report_dict['macro avg']['f1-score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
