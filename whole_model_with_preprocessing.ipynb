{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import pymorphy2\n",
    "from string import punctuation\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/ksenia/progas/python/int_trans/rureviews/women-clothing-accessories.3-class.balanced.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "загружаем наш датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path, sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>качество плохое пошив ужасный (горловина напер...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Товар отдали другому человеку, я не получила п...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ужасная синтетика! Тонкая, ничего общего с пре...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>товар не пришел, продавец продлил защиту без м...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Кофточка голая синтетика, носить не возможно.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89995</th>\n",
       "      <td>сделано достаточно хорошо. на ткани сделан рис...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89996</th>\n",
       "      <td>Накидка шикарная. Спасибо большое провдо линяе...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89997</th>\n",
       "      <td>спасибо большое ) продовца рекомендую.. заказа...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89998</th>\n",
       "      <td>Очень довольна заказом! Меньше месяца в РБ.  К...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89999</th>\n",
       "      <td>хорошая куртка. постороннего запаха нет. швы р...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      качество плохое пошив ужасный (горловина напер...  negative\n",
       "1      Товар отдали другому человеку, я не получила п...  negative\n",
       "2      Ужасная синтетика! Тонкая, ничего общего с пре...  negative\n",
       "3      товар не пришел, продавец продлил защиту без м...  negative\n",
       "4          Кофточка голая синтетика, носить не возможно.  negative\n",
       "...                                                  ...       ...\n",
       "89995  сделано достаточно хорошо. на ткани сделан рис...  positive\n",
       "89996  Накидка шикарная. Спасибо большое провдо линяе...  positive\n",
       "89997  спасибо большое ) продовца рекомендую.. заказа...  positive\n",
       "89998  Очень довольна заказом! Меньше месяца в РБ.  К...  positive\n",
       "89999  хорошая куртка. постороннего запаха нет. швы р...  positive\n",
       "\n",
       "[90000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "загружаем стоп-слова и лемматизаторы для английского и для русского (потому что в датасете перемешанные языки)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ksenia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "russian_stopwords = nltk.corpus.stopwords.words(\"russian\")\n",
    "english_stopwords = nltk.corpus.stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus_lemmatizer = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ksenia/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/ksenia/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "eng_lemmatizer = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus_pattern = re.compile(r'[А-я]+')\n",
    "eng_pattern = re.compile(r'[A-z]+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": nltk.corpus.wordnet.ADJ,\n",
    "                \"N\": nltk.corpus.wordnet.NOUN,\n",
    "                \"V\": nltk.corpus.wordnet.VERB,\n",
    "                \"R\": nltk.corpus.wordnet.ADV}\n",
    "    return tag_dict.get(tag, nltk.corpus.wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "удаляем из списка стоп-слова, которые могут влиять на таргет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove(word_list, words_to_remove):\n",
    "    for word in words_to_remove:\n",
    "        try:\n",
    "            word_list.remove(word)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "remove(russian_stopwords, ('не', 'никогда', 'хорошо', 'конечно'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_line(row):\n",
    "    line = row['review'].lower()\n",
    "    tokens = tokenizer.tokenize(line)\n",
    "    \n",
    "    tokens = [token for token in tokens if token not in russian_stopwords\\\n",
    "              and token != \" \" \\\n",
    "              and token.strip() not in punctuation]\n",
    "    \n",
    "    tokens = [token for token in tokens if token not in english_stopwords\\\n",
    "              and token != \" \" \\\n",
    "              and token.strip() not in punctuation]\n",
    "    \n",
    "    normal_forms = []\n",
    "    for token in tokens:\n",
    "        if rus_pattern.match(token):\n",
    "            normal_form = rus_lemmatizer.parse(token)[0].normal_form\n",
    "            if normal_form not in russian_stopwords:    \n",
    "                normal_forms.append(normal_form)\n",
    "        elif eng_pattern.match(token):\n",
    "            normal_form = eng_lemmatizer.lemmatize(token, get_wordnet_pos(token))\n",
    "            if normal_form not in english_stopwords:    \n",
    "                normal_forms.append(normal_form)\n",
    "                \n",
    "    row['tokens'] = normal_forms\n",
    "    row['strat_kfold'] = '{}_{}'.format(row['sentiment'], len(normal_forms))\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchnlp.word_to_vector import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_embeddings = FastText(language='ru')\n",
    "en_embeddings = FastText(language='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "препроцессинг датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90000/90000 [03:14<00:00, 462.58it/s]\n"
     ]
    }
   ],
   "source": [
    "df = df.progress_apply(preprocess_line, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokens</th>\n",
       "      <th>strat_kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>качество плохое пошив ужасный (горловина напер...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[качество, плохой, пошив, ужасный, горловина, ...</td>\n",
       "      <td>negative_21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Товар отдали другому человеку, я не получила п...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[товар, отдать, человек, не, получить, посылка...</td>\n",
       "      <td>negative_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ужасная синтетика! Тонкая, ничего общего с пре...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[ужасный, синтетик, тонкий, общий, представить...</td>\n",
       "      <td>negative_20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>товар не пришел, продавец продлил защиту без м...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[товар, не, прийти, продавец, продлить, защита...</td>\n",
       "      <td>negative_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Кофточка голая синтетика, носить не возможно.</td>\n",
       "      <td>negative</td>\n",
       "      <td>[кофточка, голый, синтетик, носить, не, возможно]</td>\n",
       "      <td>negative_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89995</th>\n",
       "      <td>сделано достаточно хорошо. на ткани сделан рис...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[сделать, достаточно, хорошо, ткань, сделать, ...</td>\n",
       "      <td>positive_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89996</th>\n",
       "      <td>Накидка шикарная. Спасибо большое провдо линяе...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[накидка, шикарный, спасибо, большой, провдо, ...</td>\n",
       "      <td>positive_15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89997</th>\n",
       "      <td>спасибо большое ) продовца рекомендую.. заказа...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[спасибо, большой, продовца, рекомендовать, за...</td>\n",
       "      <td>positive_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89998</th>\n",
       "      <td>Очень довольна заказом! Меньше месяца в РБ.  К...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[очень, довольный, заказ, маленький, месяц, рб...</td>\n",
       "      <td>positive_15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89999</th>\n",
       "      <td>хорошая куртка. постороннего запаха нет. швы р...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[хороший, куртка, посторонний, запах, шов, ров...</td>\n",
       "      <td>positive_16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment  \\\n",
       "0      качество плохое пошив ужасный (горловина напер...  negative   \n",
       "1      Товар отдали другому человеку, я не получила п...  negative   \n",
       "2      Ужасная синтетика! Тонкая, ничего общего с пре...  negative   \n",
       "3      товар не пришел, продавец продлил защиту без м...  negative   \n",
       "4          Кофточка голая синтетика, носить не возможно.  negative   \n",
       "...                                                  ...       ...   \n",
       "89995  сделано достаточно хорошо. на ткани сделан рис...  positive   \n",
       "89996  Накидка шикарная. Спасибо большое провдо линяе...  positive   \n",
       "89997  спасибо большое ) продовца рекомендую.. заказа...  positive   \n",
       "89998  Очень довольна заказом! Меньше месяца в РБ.  К...  positive   \n",
       "89999  хорошая куртка. постороннего запаха нет. швы р...  positive   \n",
       "\n",
       "                                                  tokens  strat_kfold  \n",
       "0      [качество, плохой, пошив, ужасный, горловина, ...  negative_21  \n",
       "1      [товар, отдать, человек, не, получить, посылка...   negative_9  \n",
       "2      [ужасный, синтетик, тонкий, общий, представить...  negative_20  \n",
       "3      [товар, не, прийти, продавец, продлить, защита...   negative_9  \n",
       "4      [кофточка, голый, синтетик, носить, не, возможно]   negative_6  \n",
       "...                                                  ...          ...  \n",
       "89995  [сделать, достаточно, хорошо, ткань, сделать, ...  positive_13  \n",
       "89996  [накидка, шикарный, спасибо, большой, провдо, ...  positive_15  \n",
       "89997  [спасибо, большой, продовца, рекомендовать, за...   positive_6  \n",
       "89998  [очень, довольный, заказ, маленький, месяц, рб...  positive_15  \n",
       "89999  [хороший, куртка, посторонний, запах, шов, ров...  positive_16  \n",
       "\n",
       "[90000 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "делаем стратифайд кфолд из 5 фолдов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ksenia/frow_home_projects/env/lib/python3.6/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "for fold_number, (train_index, val_index) in enumerate(stratified_kfold.split(X=df.index, y=df['strat_kfold'])):\n",
    "    df.loc[df.iloc[val_index].index, 'fold'] = fold_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokens</th>\n",
       "      <th>strat_kfold</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>качество плохое пошив ужасный (горловина напер...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[качество, плохой, пошив, ужасный, горловина, ...</td>\n",
       "      <td>negative_21</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Товар отдали другому человеку, я не получила п...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[товар, отдать, человек, не, получить, посылка...</td>\n",
       "      <td>negative_9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ужасная синтетика! Тонкая, ничего общего с пре...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[ужасный, синтетик, тонкий, общий, представить...</td>\n",
       "      <td>negative_20</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>товар не пришел, продавец продлил защиту без м...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[товар, не, прийти, продавец, продлить, защита...</td>\n",
       "      <td>negative_9</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Кофточка голая синтетика, носить не возможно.</td>\n",
       "      <td>negative</td>\n",
       "      <td>[кофточка, голый, синтетик, носить, не, возможно]</td>\n",
       "      <td>negative_6</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89995</th>\n",
       "      <td>сделано достаточно хорошо. на ткани сделан рис...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[сделать, достаточно, хорошо, ткань, сделать, ...</td>\n",
       "      <td>positive_13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89996</th>\n",
       "      <td>Накидка шикарная. Спасибо большое провдо линяе...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[накидка, шикарный, спасибо, большой, провдо, ...</td>\n",
       "      <td>positive_15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89997</th>\n",
       "      <td>спасибо большое ) продовца рекомендую.. заказа...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[спасибо, большой, продовца, рекомендовать, за...</td>\n",
       "      <td>positive_6</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89998</th>\n",
       "      <td>Очень довольна заказом! Меньше месяца в РБ.  К...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[очень, довольный, заказ, маленький, месяц, рб...</td>\n",
       "      <td>positive_15</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89999</th>\n",
       "      <td>хорошая куртка. постороннего запаха нет. швы р...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[хороший, куртка, посторонний, запах, шов, ров...</td>\n",
       "      <td>positive_16</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment  \\\n",
       "0      качество плохое пошив ужасный (горловина напер...  negative   \n",
       "1      Товар отдали другому человеку, я не получила п...  negative   \n",
       "2      Ужасная синтетика! Тонкая, ничего общего с пре...  negative   \n",
       "3      товар не пришел, продавец продлил защиту без м...  negative   \n",
       "4          Кофточка голая синтетика, носить не возможно.  negative   \n",
       "...                                                  ...       ...   \n",
       "89995  сделано достаточно хорошо. на ткани сделан рис...  positive   \n",
       "89996  Накидка шикарная. Спасибо большое провдо линяе...  positive   \n",
       "89997  спасибо большое ) продовца рекомендую.. заказа...  positive   \n",
       "89998  Очень довольна заказом! Меньше месяца в РБ.  К...  positive   \n",
       "89999  хорошая куртка. постороннего запаха нет. швы р...  positive   \n",
       "\n",
       "                                                  tokens  strat_kfold  fold  \n",
       "0      [качество, плохой, пошив, ужасный, горловина, ...  negative_21   0.0  \n",
       "1      [товар, отдать, человек, не, получить, посылка...   negative_9   2.0  \n",
       "2      [ужасный, синтетик, тонкий, общий, представить...  negative_20   1.0  \n",
       "3      [товар, не, прийти, продавец, продлить, защита...   negative_9   4.0  \n",
       "4      [кофточка, голый, синтетик, носить, не, возможно]   negative_6   2.0  \n",
       "...                                                  ...          ...   ...  \n",
       "89995  [сделать, достаточно, хорошо, ткань, сделать, ...  positive_13   0.0  \n",
       "89996  [накидка, шикарный, спасибо, большой, провдо, ...  positive_15   1.0  \n",
       "89997  [спасибо, большой, продовца, рекомендовать, за...   positive_6   3.0  \n",
       "89998  [очень, довольный, заказ, маленький, месяц, рб...  positive_15   2.0  \n",
       "89999  [хороший, куртка, посторонний, запах, шов, ров...  positive_16   2.0  \n",
       "\n",
       "[90000 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "удаляем строки, которые после препроцессинга растеряли все слова (их немного, около 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['tokens'].apply(len) != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "делаем датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetRetriever(Dataset):\n",
    "    def __init__(self, df_dataset):\n",
    "        super().__init__()\n",
    "        self.df_dataset = df_dataset\n",
    "        self.index_values = df_dataset.index.values\n",
    "        \n",
    "    def __getitem__(self, index: int):\n",
    "#         print(index)\n",
    "        row = self.df_dataset.loc[self.index_values[index]]\n",
    "        \n",
    "        tensor = torch.zeros([100, 300], dtype=torch.float32)\n",
    "        \n",
    "        for i, token in enumerate(row['tokens']):\n",
    "            if i >= 100:\n",
    "                break\n",
    "            \n",
    "            if rus_pattern.match(token):\n",
    "                tensor[i, :] = ru_embeddings[token]\n",
    "            elif eng_pattern.match(token):\n",
    "                tensor[i, :] = en_embeddings[token]\n",
    "        \n",
    "        label = 0\n",
    "        if row['sentiment'] == 'neautral':\n",
    "            label = 1\n",
    "        elif row['sentiment'] == 'positive':\n",
    "            label = 2\n",
    "            \n",
    "        return tensor, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.index_values.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_number = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DatasetRetriever(df[df['fold'] != fold_number])\n",
    "val_dataset = DatasetRetriever(df[df['fold'] == fold_number])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "проверяем, что датасет построился корректно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.5515, -0.0717, -0.1112,  ...,  0.2617,  0.4814, -0.4449],\n",
       "         [ 0.1840,  0.2454, -0.2898,  ..., -0.1282, -0.2901,  0.4213],\n",
       "         [-0.0395, -0.2272,  0.1935,  ..., -0.0100, -0.1458,  0.0633],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]),\n",
       " 0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "создаем переменные для нейронки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "batch_size = 128\n",
    "num_workers = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    sampler=RandomSampler(train_dataset),\n",
    "    pin_memory=False,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=False,\n",
    "    sampler=SequentialSampler(val_dataset),\n",
    "    pin_memory=False,\n",
    "    collate_fn=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super(Model, self).__init__()\n",
    "                \n",
    "        dim1, dim2  = 8, 16\n",
    "        \n",
    "        self.cnn_layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(dim_in, dim1, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            torch.nn.BatchNorm1d(num_features=dim1),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Conv1d(dim1, dim2, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            torch.nn.BatchNorm1d(num_features=dim2),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.cnn_layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(dim_in, dim1, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            torch.nn.BatchNorm1d(num_features=dim1),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Conv1d(dim1, dim2, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            torch.nn.BatchNorm1d(num_features=dim2),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.cnn_layer3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(dim_in, dim1, kernel_size=5, stride=1, padding=2, bias=False),\n",
    "            torch.nn.BatchNorm1d(num_features=dim1),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Conv1d(dim1, dim2, kernel_size=5, stride=1, padding=2, bias=False),\n",
    "            torch.nn.BatchNorm1d(num_features=dim2),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.cnn_layer4 = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(dim_in, dim1, kernel_size=7, stride=1, padding=3, bias=False),\n",
    "            torch.nn.BatchNorm1d(num_features=dim1),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Conv1d(dim1, dim2, kernel_size=7, stride=1, padding=3, bias=False),\n",
    "            torch.nn.BatchNorm1d(num_features=dim2),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.cnn_layer5 = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(dim_in, dim1, kernel_size=9, stride=1, padding=4, bias=False),\n",
    "            torch.nn.BatchNorm1d(num_features=dim1),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Conv1d(dim1, dim2, kernel_size=9, stride=1, padding=4, bias=False),\n",
    "            torch.nn.BatchNorm1d(num_features=dim2),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.max_pool1 = torch.nn.MaxPool1d(kernel_size=2)\n",
    "        self.max_pool2 = torch.nn.MaxPool1d(kernel_size=2)\n",
    "        self.max_pool3 = torch.nn.MaxPool1d(kernel_size=2)\n",
    "        self.max_pool4 = torch.nn.MaxPool1d(kernel_size=2)\n",
    "        self.max_pool5 = torch.nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        self.linear1 = torch.nn.Linear(12000, dim_out)\n",
    "        \n",
    "    def forward(self, matrix):\n",
    "        x1 = self.cnn_layer1(matrix)\n",
    "        x2 = self.cnn_layer2(matrix)\n",
    "        x3 = self.cnn_layer3(matrix)\n",
    "        x4 = self.cnn_layer4(matrix)\n",
    "        x5 = self.cnn_layer5(matrix)\n",
    "        \n",
    "        x1 = self.max_pool1(x1)\n",
    "        x2 = self.max_pool2(x2)\n",
    "        x3 = self.max_pool3(x3)\n",
    "        x4 = self.max_pool4(x4)\n",
    "        x5 = self.max_pool5(x5)\n",
    "        \n",
    "        x1 = torch.flatten(x1, 1)\n",
    "        x2 = torch.flatten(x2, 1)\n",
    "        x3 = torch.flatten(x3, 1)\n",
    "        x4 = torch.flatten(x4, 1)\n",
    "        x5 = torch.flatten(x5, 1)\n",
    "        \n",
    "        x6 = torch.cat((x1, x2, x3, x4, x5), dim=1)\n",
    "        x7 = self.linear1(x6)\n",
    "        \n",
    "        return x7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(100, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "проверяем, что батч запихивается в сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 100, 300])\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.stack((data[0], data[0], data[0]))\n",
    "print(input_tensor.shape)\n",
    "output = model(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4321, -0.0324,  0.3626],\n",
       "        [ 0.4321, -0.0324,  0.3626],\n",
       "        [ 0.4321, -0.0324,  0.3626]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "дальше будет обучение "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.011453495025634766 1.1453495025634766\n",
      "100 0.9870296752452851 0.821228563785553\n",
      "200 0.7736449813842774 0.812629759311676\n",
      "300 0.7386571186780929 0.6705959439277649\n",
      "400 0.7328903269767761 1.0365992784500122\n",
      "500 0.7220871156454086 0.628259539604187\n",
      "----------------------------------------------\n",
      "loss:   0.7107365685449519\n",
      "accuracy:   87.37323943661971\n",
      "[[3192 2635  204]\n",
      " [ 807 4551  654]\n",
      " [ 131 1224 4664]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.53      0.63      6031\n",
      "           1       0.54      0.76      0.63      6012\n",
      "           2       0.84      0.77      0.81      6019\n",
      "\n",
      "   micro avg       0.69      0.69      0.69     18062\n",
      "   macro avg       0.72      0.69      0.69     18062\n",
      "weighted avg       0.72      0.69      0.69     18062\n",
      "\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "0 0.006469257473945618 0.6469257473945618\n",
      "100 0.6540451401472092 0.6819949150085449\n",
      "200 0.6709786087274552 0.6410307288169861\n",
      "300 0.6769006302952767 0.6070649027824402\n",
      "400 0.6675137931108475 0.609346866607666\n",
      "500 0.6605035689473152 0.5993168354034424\n",
      "----------------------------------------------\n",
      "loss:   0.7008171098333009\n",
      "accuracy:   87.58450704225352\n",
      "[[3480 2083  468]\n",
      " [1028 3877 1107]\n",
      " [ 143  796 5080]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.58      0.65      6031\n",
      "           1       0.57      0.64      0.61      6012\n",
      "           2       0.76      0.84      0.80      6019\n",
      "\n",
      "   micro avg       0.69      0.69      0.69     18062\n",
      "   macro avg       0.70      0.69      0.69     18062\n",
      "weighted avg       0.70      0.69      0.69     18062\n",
      "\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "0 0.006414957642555237 0.6414957642555237\n",
      "100 0.610946663916111 0.5681437253952026\n",
      "200 0.6209740704298019 0.5654224753379822\n",
      "300 0.6323901247978211 0.6482715010643005\n",
      "400 0.6437072613835335 0.5122299194335938\n",
      "500 0.6260349369049072 0.6646671295166016\n",
      "----------------------------------------------\n",
      "loss:   0.7097622021822863\n",
      "accuracy:   87.06338028169014\n",
      "[[4574 1326  131]\n",
      " [2195 3309  508]\n",
      " [ 403 1136 4480]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.76      0.69      6031\n",
      "           1       0.57      0.55      0.56      6012\n",
      "           2       0.88      0.74      0.80      6019\n",
      "\n",
      "   micro avg       0.68      0.68      0.68     18062\n",
      "   macro avg       0.70      0.68      0.69     18062\n",
      "weighted avg       0.70      0.68      0.69     18062\n",
      "\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "0 0.006464992761611939 0.6464992761611938\n",
      "100 0.5814099502563477 0.525459885597229\n",
      "200 0.5935749781131744 0.6093119978904724\n",
      "300 0.6062789806723594 0.704787015914917\n",
      "400 0.6058853965997696 0.6482072472572327\n",
      "500 0.6119869554042816 0.6427180767059326\n",
      "----------------------------------------------\n",
      "loss:   0.7136133617498506\n",
      "accuracy:   87.71126760563381\n",
      "[[3780 2084  167]\n",
      " [1372 4092  548]\n",
      " [ 237 1199 4583]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.63      0.66      6031\n",
      "           1       0.55      0.68      0.61      6012\n",
      "           2       0.87      0.76      0.81      6019\n",
      "\n",
      "   micro avg       0.69      0.69      0.69     18062\n",
      "   macro avg       0.71      0.69      0.69     18062\n",
      "weighted avg       0.71      0.69      0.69     18062\n",
      "\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "0 0.005089278817176818 0.5089278817176819\n",
      "100 0.5456508064270019 0.5563297867774963\n",
      "200 0.5624186253547668 0.4933624267578125\n",
      "300 0.5831165805459022 0.6367099285125732\n",
      "400 0.5982565632462502 0.609123170375824\n",
      "500 0.5859061962366104 0.540967583656311\n",
      "----------------------------------------------\n",
      "loss:   0.7181294594012516\n",
      "accuracy:   87.2605633802817\n",
      "[[3912 1869  250]\n",
      " [1549 3646  817]\n",
      " [ 249  937 4833]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.65      0.67      6031\n",
      "           1       0.57      0.61      0.59      6012\n",
      "           2       0.82      0.80      0.81      6019\n",
      "\n",
      "   micro avg       0.69      0.69      0.69     18062\n",
      "   macro avg       0.69      0.69      0.69     18062\n",
      "weighted avg       0.69      0.69      0.69     18062\n",
      "\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "0 0.004911551177501678 0.49115511775016785\n",
      "100 0.5346452528238297 0.6311947703361511\n",
      "200 0.556570961177349 0.625761091709137\n",
      "300 0.554705995619297 0.5199606418609619\n",
      "400 0.5530889025330543 0.5214495658874512\n",
      "500 0.5501243728399277 0.5390170216560364\n",
      "----------------------------------------------\n",
      "loss:   0.7561161500257505\n",
      "accuracy:   85.63380281690141\n",
      "[[3476 1942  613]\n",
      " [1113 3411 1488]\n",
      " [ 135  611 5273]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.58      0.65      6031\n",
      "           1       0.57      0.57      0.57      6012\n",
      "           2       0.72      0.88      0.79      6019\n",
      "\n",
      "   micro avg       0.67      0.67      0.67     18062\n",
      "   macro avg       0.67      0.67      0.67     18062\n",
      "weighted avg       0.67      0.67      0.67     18062\n",
      "\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "0 0.005128057599067688 0.5128057599067688\n",
      "100 0.5043712803721427 0.509390652179718\n",
      "200 0.49810435622930527 0.5456133484840393\n",
      "300 0.5170170736312866 0.5446847081184387\n",
      "400 0.53330920368433 0.5335863828659058\n",
      "500 0.5545066118240356 0.6106396913528442\n",
      "----------------------------------------------\n",
      "loss:   0.7638131598351707\n",
      "accuracy:   86.47183098591549\n",
      "[[3257 2556  218]\n",
      " [ 965 4333  714]\n",
      " [ 150 1180 4689]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.54      0.63      6031\n",
      "           1       0.54      0.72      0.62      6012\n",
      "           2       0.83      0.78      0.81      6019\n",
      "\n",
      "   micro avg       0.68      0.68      0.68     18062\n",
      "   macro avg       0.71      0.68      0.68     18062\n",
      "weighted avg       0.71      0.68      0.68     18062\n",
      "\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "0 0.005616798996925354 0.5616798996925354\n",
      "100 0.4937563705444336 0.5560125708580017\n",
      "200 0.49876099288463593 0.5317859053611755\n",
      "300 0.5012117552757264 0.44174155592918396\n",
      "400 0.5149508103728294 0.5344095826148987\n",
      "500 0.5136717146635056 0.5794762969017029\n",
      "----------------------------------------------\n",
      "loss:   0.765840673740481\n",
      "accuracy:   86.59154929577464\n",
      "[[4437 1298  296]\n",
      " [2137 2899  976]\n",
      " [ 356  703 4960]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.68      6031\n",
      "           1       0.59      0.48      0.53      6012\n",
      "           2       0.80      0.82      0.81      6019\n",
      "\n",
      "   micro avg       0.68      0.68      0.68     18062\n",
      "   macro avg       0.68      0.68      0.68     18062\n",
      "weighted avg       0.68      0.68      0.68     18062\n",
      "\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "0 0.004800368547439576 0.4800368547439575\n",
      "100 0.4613185605406761 0.4755781590938568\n",
      "200 0.4853628066182136 0.4645136892795563\n",
      "300 0.4787077862024307 0.6093698143959045\n",
      "400 0.49198021352291105 0.5445994138717651\n",
      "500 0.48627584606409074 0.4007384777069092\n",
      "----------------------------------------------\n",
      "loss:   0.8761256977286137\n",
      "accuracy:   84.24647887323944\n",
      "[[4537 1390  104]\n",
      " [2290 3341  381]\n",
      " [ 547 1387 4085]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.75      0.68      6031\n",
      "           1       0.55      0.56      0.55      6012\n",
      "           2       0.89      0.68      0.77      6019\n",
      "\n",
      "   micro avg       0.66      0.66      0.66     18062\n",
      "   macro avg       0.69      0.66      0.67     18062\n",
      "weighted avg       0.69      0.66      0.67     18062\n",
      "\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "0 0.004670129120349884 0.4670129120349884\n",
      "100 0.4583063384890556 0.3538144528865814\n",
      "200 0.45782932102680207 0.35047629475593567\n",
      "300 0.4722781118750572 0.5146508812904358\n",
      "400 0.4648604437708855 0.542242705821991\n",
      "500 0.4793996000289917 0.42157459259033203\n",
      "----------------------------------------------\n",
      "loss:   0.8604594746106108\n",
      "accuracy:   85.19014084507042\n",
      "[[4169 1752  110]\n",
      " [1818 3735  459]\n",
      " [ 424 1402 4193]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.69      0.67      6031\n",
      "           1       0.54      0.62      0.58      6012\n",
      "           2       0.88      0.70      0.78      6019\n",
      "\n",
      "   micro avg       0.67      0.67      0.67     18062\n",
      "   macro avg       0.69      0.67      0.68     18062\n",
      "weighted avg       0.69      0.67      0.68     18062\n",
      "\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # train\n",
    "    \n",
    "    for batch_idx, (matrices, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch_tensor = torch.stack(matrices).to(device)\n",
    "        labels_tensor = torch.tensor(labels).to(device)\n",
    "        \n",
    "        outputs = model(batch_tensor)\n",
    "        loss = criterion(outputs, labels_tensor)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print(batch_idx, running_loss/100, loss.item())\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    running_loss = 0.0\n",
    "    accuracy = 0\n",
    "    pred_array = []\n",
    "    label_array = []\n",
    "\n",
    "    #test\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (matrices, labels) in enumerate(val_loader):\n",
    "            batch_tensor = torch.stack(matrices).to(device)\n",
    "            labels_tensor = torch.tensor(labels).to(device)\n",
    "\n",
    "            outputs = model(batch_tensor)\n",
    "            loss = criterion(outputs, labels_tensor)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            pred_array += torch.argmax(outputs, dim=1).tolist()\n",
    "            label_array += labels_tensor.tolist()\n",
    "\n",
    "            accurate_predicted = torch.sum(torch.argmax(outputs, dim=1) == labels_tensor).item()\n",
    "            accuracy += accurate_predicted\n",
    "\n",
    "    print('----------------------------------------------')\n",
    "    print('loss:  ', running_loss/len(val_loader))\n",
    "    print('accuracy:  ', accuracy / len(val_loader))\n",
    "    print(confusion_matrix(label_array, pred_array))\n",
    "    print(classification_report(label_array, pred_array))\n",
    "    print('----------------------------------------------\\n\\n\\n')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
